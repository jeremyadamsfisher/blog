<!DOCTYPE html><html lang=en class=has-navbar-fixed-top><head><title>Jeremy Fisher :: Loading {Gen,Prote}omic Sequences for Deep Learning: FASTA to PyTorch</title><meta charset=utf-8><meta name=generator content=Pelican><meta name=viewport content="width=device-width, initial-scale=1"><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=stylesheet href=https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=./theme/css/bulma.css><link rel=stylesheet href=./theme/css/style-1.0.css><script src=./theme/js/navbar.js></script><link rel=stylesheet href=./theme/highlight/monokai.css><script src=./theme/js/highlight.pack.js></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body id=index class=home><nav id=main-navbar class="navbar is-light is-fixed-top" role=navigation aria-label="main navigation"><div class=navbar-brand><a href=/ class=navbar-item><strong id=brand>Jeremy Fisher</strong></a><a role=button class="navbar-burger burger" aria-label=menu aria-expanded=false data-target=navbarBasicExample><span aria-hidden=true></span><span aria-hidden=true></span><span aria-hidden=true></span></a></div><div id=navbarBasicExample class=navbar-menu><div class=navbar-start></div><div class=navbar-end><a href=./ class=navbar-item>About</a><a class=navbar-item href=/blog>Blog</a></div></div></nav><div class=j-content-container><div class="j-content content"><section><header><h3><a class=article-title href=./loading-genproteomic-sequences-for-deep-learning-fasta-to-pytorch.html rel=bookmark title="Permalink to Loading {Gen,Prote}omic Sequences for Deep Learning: FASTA to PyTorch">Loading {Gen,Prote}omic Sequences for Deep Learning: FASTA to PyTorch</a></h3></header><footer class=post-info><i class="fa fa-calendar"></i><time class=published datetime=2020-05-28T10:02:00+02:00> Thu 28 May 2020 </time></footer><hr><div class=entry-content><p>Most deep learning tools for sequence modeling target Natural Language Processing. I mean, I love NLP, but I'm doing genomics! Why doesn't Google or Facebook make a utility library for <em>my</em> highly specific use-case?</p><p>Anyways, I found myself in need of ingesting protein sequences into PyTorch. There are many ways to do this: finding the "best" computational representation (e.g., GloVe, k-mer frequency, etc) of a protein polymer was the goal of my research project. The goal for this post is to demonstrate a simple, albeit complete system to ingest biological sequences from FASTA files.</p><p>The absolute first step is to load the sequence data. For convenience, I load it into memory. (It is possible to load these sequences from disk as needed using <a href=https://pytorch.org/docs/stable/data.html#iterable-style-datasets>iterable-style datasets</a>, but this precludes batching!)</p><div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>Bio</span> <span class=kn>import</span> <span class=n>SeqIO</span>
<span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&quot;foo.fasta&quot;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
    <span class=n>records</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>SeqIO</span><span class=o>.</span><span class=n>parse</span><span class=p>(</span><span class=n>f</span><span class=p>,</span> <span class=s2>&quot;fasta&quot;</span><span class=p>))</span>
</code></pre></div><p>The first step is to run through the genomic data so we know which residues are present. This allows us to assign each a unique number.</p><div class=highlight><pre><span></span><code><span class=n>vocab</span> <span class=o>=</span> <span class=nb>set</span><span class=p>()</span>
<span class=k>for</span> <span class=n>record</span> <span class=ow>in</span> <span class=n>records</span><span class=p>:</span>
    <span class=n>vocab</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>record</span><span class=o>.</span><span class=n>seq</span><span class=p>))</span>
<span class=n>vocab</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=s2>&quot;&lt;pad&gt;&quot;</span><span class=p>)</span>
<span class=n>to_ix</span> <span class=o>=</span> <span class=p>{</span><span class=n>char</span><span class=p>:</span> <span class=n>i</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>char</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>vocab</span><span class=p>)}</span>
</code></pre></div><p>For example, a random protein from the <a href=https://www.uniprot.org/proteomes/UP000000399>Grapevine Fleck Virus</a> is encoded thusly:</p><div class=highlight><pre><span></span><code><span class=p>[</span><span class=n>to_ix</span><span class=p>[</span><span class=n>residue</span><span class=p>]</span> <span class=k>for</span> <span class=n>residue</span> <span class=ow>in</span> <span class=s2>&quot;MNRGPPLRSRPPSSPPPASAFPGPSPFPSPSPANSLPSASPPPPTCTPSSPVSRPFASARLRTSHPPRCPHRSAPPSAPSPPFTPPHPLPTPTPSSSPRSPWLSLAPLPTSSASLASFPPPPSSFSSPSSPSTSPLSPSSSSFPSSSSFSFLVPSNS&quot;</span><span class=p>]</span>
<span class=o>&gt;&gt;&gt;</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>11</span><span class=p>]</span>
</code></pre></div><p>This is the simplest possible embedding. How do we get this into PyTorch? By defining a dataset -- which is just a class with definitions for <code>__getitem__</code> and <code>__len__</code> and passing this to a <code>torch.utils.data.DataLoader</code> instance. For the unaware, these are "dunder" or "magic" methods, which you can read about <a href=https://rszalski.github.io/magicmethods/ >here</a>. We can write a simplistic (read: flawed) implementation like so:</p><div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>

<span class=k>class</span> <span class=nc>BiologicalSequenceDataset</span><span class=p>:</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>records</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>records</span> <span class=o>=</span> <span class=n>records</span>

    <span class=k>def</span> <span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>records</span><span class=p>)</span>

    <span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>i</span><span class=p>):</span>
        <span class=n>seq</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>records</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>seq</span>
        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>to_ix</span><span class=p>[</span><span class=n>residue</span><span class=p>]</span> <span class=k>for</span> <span class=n>residue</span> <span class=ow>in</span> <span class=n>seq</span><span class=p>])</span>

<span class=n>training_data</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span>
    <span class=n>BiologicalSequenceDataset</span><span class=p>(</span><span class=n>records</span><span class=p>),</span>
    <span class=n>batch_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
<span class=p>)</span>
</code></pre></div><p>This would work, actually, but only because I have specified the batch size as 1. Any more and we would get an error about tensors of different sizes. To address this issue, we implement a <code>collate_fn</code> as described <a href=https://pytorch.org/docs/stable/data.html#dataloader-collate-fn>here</a>. This will take a set of arbitrary sequences and zero-pad the shorter ones, such that they're all the same length.</p><div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>collate_fn</span><span class=p>(</span><span class=n>batch</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>pad_sequence</span><span class=p>(</span>
        <span class=n>batch</span><span class=p>,</span>
        <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
        <span class=n>padding_value</span><span class=o>=</span><span class=n>to_ix</span><span class=p>[</span><span class=s2>&quot;&lt;pad&gt;&quot;</span><span class=p>]</span>
    <span class=p>)</span>
</code></pre></div><p>Then, the dataloader would be modified like so:</p><div class=highlight><pre><span></span><code><span class=n>training_data</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span>
    <span class=n>BiologicalSequenceDataset</span><span class=p>(</span><span class=n>records</span><span class=p>),</span>
    <span class=n>collate_fn</span><span class=o>=</span><span class=n>collate_fn</span><span class=p>,</span>
<span class=p>)</span>
</code></pre></div><h2>The complete code</h2><p>If we make one adjustment to partition testing and training data, we have:</p><div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>from</span> <span class=nn>Bio</span> <span class=kn>import</span> <span class=n>SeqIO</span>

<span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&quot;foo.fasta&quot;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
    <span class=n>records</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>SeqIO</span><span class=o>.</span><span class=n>parse</span><span class=p>(</span><span class=n>f</span><span class=p>,</span> <span class=s2>&quot;fasta&quot;</span><span class=p>))</span>

<span class=n>vocab</span> <span class=o>=</span> <span class=nb>set</span><span class=p>()</span>
<span class=k>for</span> <span class=n>record</span> <span class=ow>in</span> <span class=n>records</span><span class=p>:</span>
    <span class=n>vocab</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>record</span><span class=o>.</span><span class=n>seq</span><span class=p>))</span>
<span class=n>vocab</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=s2>&quot;&lt;pad&gt;&quot;</span><span class=p>)</span>
<span class=n>to_ix</span> <span class=o>=</span> <span class=p>{</span><span class=n>char</span><span class=p>:</span> <span class=n>i</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>char</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>vocab</span><span class=p>)}</span>


<span class=k>class</span> <span class=nc>BiologicalSequenceDataset</span><span class=p>:</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>records</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>records</span> <span class=o>=</span> <span class=n>records</span>

    <span class=k>def</span> <span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>records</span><span class=p>)</span>

    <span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>i</span><span class=p>):</span>
        <span class=n>seq</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>records</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>seq</span>
        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>to_ix</span><span class=p>[</span><span class=n>residue</span><span class=p>]</span> <span class=k>for</span> <span class=n>residue</span> <span class=ow>in</span> <span class=n>seq</span><span class=p>])</span>


<span class=k>def</span> <span class=nf>collate_fn</span><span class=p>(</span><span class=n>batch</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>rnn</span><span class=o>.</span><span class=n>pad_sequence</span><span class=p>(</span>
        <span class=n>batch</span><span class=p>,</span>
        <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
        <span class=n>padding_value</span><span class=o>=</span><span class=n>to_ix</span><span class=p>[</span><span class=s2>&quot;&lt;pad&gt;&quot;</span><span class=p>]</span>
    <span class=p>)</span>

<span class=n>n_examples</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>records</span><span class=p>)</span>
<span class=n>ds_train</span><span class=p>,</span> <span class=n>ds_test</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>random_split</span><span class=p>(</span>
    <span class=n>BiologicalSequenceDataset</span><span class=p>(</span><span class=n>records</span><span class=p>),</span>
    <span class=n>lengths</span><span class=o>=</span><span class=p>[</span><span class=n>n_examples</span><span class=o>-</span><span class=p>(</span><span class=n>n_examples</span><span class=o>//</span><span class=mi>4</span><span class=p>),</span> <span class=n>n_examples</span><span class=o>//</span><span class=mi>4</span><span class=p>]</span>
<span class=p>)</span>
<span class=n>dl</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s2>&quot;train&quot;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>ds_train</span><span class=p>,</span> <span class=n>collate_fn</span><span class=o>=</span><span class=n>collate_fn</span><span class=p>),</span>
    <span class=s2>&quot;test&quot;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>ds_test</span><span class=p>,</span> <span class=n>collate_fn</span><span class=o>=</span><span class=n>collate_fn</span><span class=p>)</span>
<span class=p>}</span>
</code></pre></div></div></section><script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
document.addEventListener('DOMContentLoaded', (event) => {
  document.querySelectorAll('pre').forEach((block) => {
    hljs.highlightBlock(block);
  });
});
</script></div></div></body></html>