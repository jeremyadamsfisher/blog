<!DOCTYPE html><html lang=en class=has-navbar-fixed-top><head><title>Jeremy Fisher :: Augmenting image landmarks along with images in PyTorch</title><meta charset=utf-8><meta name=generator content=Pelican><meta name=viewport content="width=device-width, initial-scale=1"><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=stylesheet href=https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=./theme/css/bulma.css><link rel=stylesheet href=./theme/css/style-1.0.css><script src=./theme/js/navbar.js></script><link rel=stylesheet href=./theme/highlight/monokai.css><script src=./theme/js/highlight.pack.js></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body id=index class=home><nav id=main-navbar class="navbar is-light is-fixed-top" role=navigation aria-label="main navigation"><div class=navbar-brand><a href=/ class=navbar-item><strong id=brand>Jeremy Fisher</strong></a><a role=button class="navbar-burger burger" aria-label=menu aria-expanded=false data-target=navbarBasicExample><span aria-hidden=true></span><span aria-hidden=true></span><span aria-hidden=true></span></a></div><div id=navbarBasicExample class=navbar-menu><div class=navbar-start></div><div class=navbar-end><a href=./ class=navbar-item>About</a><a class=navbar-item href=/blog>Blog</a></div></div></nav><div class=j-content-container><div class="j-content content"><section><header><h3><a class=article-title href=./augmenting-image-landmarks-along-with-images-in-pytorch.html rel=bookmark title="Permalink to Augmenting image landmarks along with images in PyTorch">Augmenting image landmarks along with images in PyTorch</a></h3></header><footer class=post-info><i class="fa fa-calendar"></i><time class=published datetime=2019-05-04T10:02:00+02:00> Sat 04 May 2019 </time></footer><hr><div class=entry-content><p>Lately, I have been working with X-ray images with positional and clinical labels. They look like this:</p><table><thead><tr><th align=center></th><th align=center>x</th><th align=center>y</th><th align=center>diagnosis</th></tr></thead><tbody><tr><td align=center>/data/img1.jpg</td><td align=center>2.1</td><td align=center>5.2</td><td align=center>0</td></tr><tr><td align=center>/data/img2.jpg</td><td align=center>2.6</td><td align=center>4.0</td><td align=center>1</td></tr></tbody></table><p>Its trivial to load these data using pandas (<code>Torch.FloatTensor(pd.read_csv(fp, index_col=0).iloc[0, :])</code>). However -- and this is typical for biomedical datasets -- my classes are very imbalanced, which means that I need to augment the heck out of it. PyTorch's built in transformations are no good for this, because they operate on images. We'll have to implement the augmentation directly using linear transformations.</p><p>By the way, I almost used FastAI for this, because they have all of these implemented through the <a href=https://docs.fast.ai/vision.image.html#ImagePoints>ImagePoints</a> module. But I decided to use PyTorch because my use case was a little unusual and I wanted the flexibility. If your use-case is more standard, I recommend using that because there will be less code to write (and a smaller bug surface).</p><p>I'll start with an obvious one: rotating landmarks along with the image. Normally, I would do something like this:</p><div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
<span class=kn>from</span> <span class=nn>torchvision</span> <span class=kn>import</span> <span class=n>transforms</span>
<span class=kn>from</span> <span class=nn>torchvision.models</span> <span class=kn>import</span> <span class=n>resnet50</span>
<span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>

<span class=k>class</span> <span class=nc>ImageWithLandmarks</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>Dataset</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>root</span><span class=p>,</span> <span class=n>labels_fp</span><span class=p>,</span> <span class=n>img_type</span><span class=o>=</span><span class=s2>&quot;jpg&quot;</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>imgs</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>Path</span><span class=p>(</span><span class=n>img_dir</span><span class=p>)</span><span class=o>.</span><span class=n>glob</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;*.</span><span class=si>{</span><span class=n>img_type</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>))</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>landmarks</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>labels_fp</span><span class=p>,</span> <span class=n>index_col</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>preprocess</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
            <span class=n>transforms</span><span class=o>.</span><span class=n>RandomRotation</span><span class=p>(</span><span class=mi>360</span><span class=p>),</span>
            <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
        <span class=p>])</span>

    <span class=k>def</span> <span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>img_dir</span><span class=p>)</span>

    <span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>i</span><span class=p>):</span>
        <span class=n>img_fp</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>imgs</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
        <span class=n>img</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>img_fp</span><span class=p>)</span>
        <span class=n>label</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>landmarks</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=n>img_fp</span><span class=p>,:]</span><span class=o>.</span><span class=n>values</span>
        <span class=c1># &gt;&gt;&gt; self.landmarks.loc[&quot;/data/img1&quot;.jpg,:].values</span>
        <span class=c1># np.array([2.1, 5.2], np.float32)</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>training</span><span class=p>:</span>
            <span class=n>img</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>rotate</span><span class=p>(</span><span class=n>random</span><span class=o>.</span><span class=n>random</span><span class=p>()</span> <span class=o>*</span> <span class=mf>360.0</span><span class=p>)</span>  <span class=c1># &lt;-</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>preprocess</span><span class=p>(</span><span class=n>img</span><span class=p>),</span> <span class=n>torch</span><span class=o>.</span><span class=n>FloatTensor</span><span class=p>(</span><span class=n>label</span><span class=p>)</span>
</code></pre></div><p>However, this won't work -- because our landmarks will not rotate with our image like so:</p><video width=320 height=240 controls loop><source src=./videos/augmentation_post/bad.mp4 type=video/mp4></video><p>The solution is to construct a <strong>rotation matrix</strong> for some specific angle, $\theta$. Since this is just linear algebra, we can easily vectorize this in numpy.</p><div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>rotate</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>pivot</span><span class=p>,</span> <span class=n>theta</span><span class=p>):</span>
    <span class=sd>&quot;&quot;&quot;rotate a vector, x, by theta (radians), around pivot vector</span>

<span class=sd>    &gt;&gt;&gt; rotate(np.array([0,1]).T, theta=np.pi/2)</span>
<span class=sd>    np.array([1, 0])</span>

<span class=sd>    Arguments:</span>
<span class=sd>        x {np.array} : vector to be rotated</span>
<span class=sd>        pivot {np.array} : pivot of the rotation</span>
<span class=sd>        theta {float} : amount of rotation</span>

<span class=sd>    Returns: rotated vector, x {np.array}</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>rotation_mat</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
        <span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>theta</span><span class=p>),</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>theta</span><span class=p>)],</span>
        <span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>theta</span><span class=p>),</span>  <span class=n>np</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>theta</span><span class=p>)]</span>
    <span class=p>])</span>
    <span class=c1># note: @ is the matrix multiplication operator in modern numpy</span>
    <span class=k>return</span> <span class=p>(</span><span class=n>rotation_mat</span> <span class=o>@</span> <span class=p>(</span><span class=n>x</span> <span class=o>-</span> <span class=n>pivot</span><span class=p>))</span> <span class=o>+</span> <span class=n>pivot</span>
</code></pre></div><p>You will notice there is a <code>pivot</code> argument. Because PIL (and, by extension, PyTorch) rotate with the center of the image as the pivot, we need to translate our coordinate system before applying the rotation.</p><p>In all, the preprocessing step becomes:</p><div class=highlight><pre><span></span><code><span class=c1># at the top of the file...</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=kn>import</span> <span class=nn>random</span>
<span class=c1># ... in the constructor ...</span>
<span class=bp>self</span><span class=o>.</span><span class=n>preprocess</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>()</span>
<span class=c1># ... in the get_item method</span>
<span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>training</span><span class=p>:</span>
    <span class=n>r</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>random</span><span class=p>()</span>
    <span class=n>rot_degs</span> <span class=o>=</span> <span class=n>r</span> <span class=o>*</span> <span class=mf>360.0</span>
    <span class=n>rot_rads</span> <span class=o>=</span> <span class=n>r</span> <span class=o>*</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>pi</span>
    <span class=n>img</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>rotate</span><span class=p>(</span><span class=n>rot_degs</span><span class=p>)</span>
    <span class=n>pivot</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>size</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span> <span class=c1># pivot around the image center</span>
    <span class=n>label</span> <span class=o>=</span> <span class=n>rotate</span><span class=p>(</span><span class=n>label</span><span class=p>,</span> <span class=n>pivot</span><span class=p>,</span> <span class=n>rot_rads</span><span class=p>)</span>
</code></pre></div><p>Now, we get this:</p><video width=320 height=240 controls loop><source src=./videos/augmentation_post/good.mp4 type=video/mp4></video><p>Much better.</p><h2>Final notes</h2><p>We don't have to compute the rotation matrix every trial. In fact, I think this is a little more error-prone, not to mention computationally expensive (although premature optimization is the root of all evil). We can precompute a set of rotation matrices like so:</p><div class=highlight><pre><span></span><code><span class=c1># precompute 100 rotation matrices</span>
<span class=n>rotations</span> <span class=o>=</span> <span class=p>[</span>
    <span class=p>(</span><span class=n>theta</span><span class=p>,</span> <span class=n>theta</span><span class=o>*</span><span class=mi>180</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>pi</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
        <span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>theta</span><span class=p>),</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>theta</span><span class=p>)],</span>
        <span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>theta</span><span class=p>),</span>  <span class=n>np</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>theta</span><span class=p>)]</span>
    <span class=p>])</span>
    <span class=k>for</span> <span class=n>theta</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=o>*</span><span class=n>np</span><span class=o>.</span><span class=n>pi</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
<span class=p>]</span> 
</code></pre></div><p>In all, the dataloader would be implemented like this:</p><div class=highlight><pre><span></span><code><span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>i</span><span class=p>):</span>
    <span class=n>img_fp</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>imgs</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
    <span class=n>img</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>img_fp</span><span class=p>)</span>
    <span class=n>label</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>landmarks</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=n>img_fp</span><span class=p>,:]</span><span class=o>.</span><span class=n>values</span>
    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>training</span><span class=p>:</span>
        <span class=n>rotation_rads</span><span class=p>,</span> <span class=n>rotation_degs</span><span class=p>,</span> <span class=n>rotation_mat</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>rotations</span><span class=p>)</span>
        <span class=n>img</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>rotate</span><span class=p>(</span><span class=n>rotation_degs</span><span class=p>)</span>
        <span class=n>pivot</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>size</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span>
        <span class=n>label</span> <span class=o>=</span> <span class=p>(</span><span class=n>rotation_mat</span> <span class=o>@</span> <span class=p>(</span><span class=n>label</span> <span class=o>-</span> <span class=n>pivot</span><span class=p>))</span> <span class=o>+</span> <span class=n>pivot</span>
    <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>preprocess</span><span class=p>(</span><span class=n>img</span><span class=p>),</span> <span class=n>torch</span><span class=o>.</span><span class=n>FloatTensor</span><span class=p>(</span><span class=n>label</span><span class=p>)</span>
</code></pre></div><p>If you do it this way, you can easily compose rotations with other linear transformations. Here are a couple:</p><p><strong>Scaling</strong>: <code>scale(a,b)</code> $\to \begin{bmatrix} a &amp; 0 \\ 0 &amp; b \end{bmatrix}$</p><p><strong>Translation</strong>: <code>translate(c,d)</code> $\to \begin{bmatrix} c &amp; d \\ \end{bmatrix}^T$</p><p><strong>Shear</strong>: <code>shear(e)</code> $\to \begin{bmatrix} 1 &amp; e \\ 0 &amp; 1 \end{bmatrix}$</p><p>These are provided for images in PyTorch transforms through the <a href=https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.functional.affine>affine transform</a> (<code>torchvision.transforms.functional.affine</code>).</p><p>Thus, <code>img = affine(img, angle=theta, translate=(a,b), scale=(c,d), shear=e)</code> corresponds to the following code for a positional label:</p><div class=highlight><pre><span></span><code><span class=n>rot_mat</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([[</span><span class=n>np</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>theta</span><span class=p>),</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>theta</span><span class=p>)],</span>
                    <span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>theta</span><span class=p>),</span>  <span class=n>np</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>theta</span><span class=p>)]])</span>
<span class=n>scale_mat</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([[</span><span class=n>a</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
                      <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>b</span><span class=p>]])</span>
<span class=n>shear_mat</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=n>m</span><span class=p>],</span>
                      <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]])</span>
<span class=n>translation_mat</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>a</span><span class=p>,</span><span class=n>b</span><span class=p>])</span><span class=o>.</span><span class=n>T</span>
<span class=n>label</span> <span class=o>=</span> <span class=p>((</span><span class=n>rot_mat</span>
          <span class=o>@</span> <span class=n>scale_mat</span>
          <span class=o>@</span> <span class=n>shear_mat</span>
          <span class=o>@</span> <span class=p>(</span><span class=n>label</span> <span class=o>-</span> <span class=n>pivot</span><span class=p>))</span>
        <span class=o>+</span> <span class=n>pivot</span>
        <span class=o>+</span> <span class=n>translation_mat</span><span class=p>)</span>
</code></pre></div><h2>Source Code</h2><p>The code for generating the visualizations above are available <a href=https://gist.github.com/jeremyadamsfisher/b4efbc75d4c5a2cde87c14e6445f1f26>here</a>. </p><h2>References:</h2><ul><li>X-ray image by Sudraben - Own work, CC BY-SA 4.0, <a href="https://commons.wikimedia.org/w/index.php?curid=75028598">https://commons.wikimedia.org/w/index.php?curid=75028598</a></li><li>Thanks <a href=https://github.com/jwkvam/celluloid>celluloid</a> for the awesome interface for matplotlib animations!</li></ul></div></section><script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
document.addEventListener('DOMContentLoaded', (event) => {
  document.querySelectorAll('pre').forEach((block) => {
    hljs.highlightBlock(block);
  });
});
</script></div></div></body></html>